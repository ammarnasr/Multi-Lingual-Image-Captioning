{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "# Read the captions from the jsonl file\n",
    "with jsonlines.open('captions/captions.jsonl') as reader:\n",
    "    captions = list(reader)\n",
    "\n",
    "target_langs = ['ar', 'en', 'fr', 'de']\n",
    "cols  =[\n",
    "    'image',\n",
    "    'arabic_caption', 'num_arabic_captions',\n",
    "    'english_caption','num_english_captions',\n",
    "    'french_caption', 'num_french_captions',\n",
    "    'german_caption', 'num_german_captions',\n",
    "    'locale'\n",
    "    ]\n",
    "\n",
    "langs_abbrev = { 'ar': 'arabic', 'en': 'english', 'fr': 'french', 'de': 'german' }\n",
    "# Create a dictionary to store the captions\n",
    "captions_dict = {col: [] for col in cols}\n",
    "\n",
    "# Loop through the captions\n",
    "for caption_item in captions:\n",
    "    # Get the image name\n",
    "    image = caption_item['image/key']\n",
    "    # Add the image name to the dictionary\n",
    "    captions_dict['image'].append(image)\n",
    "    # Get the locale\n",
    "    locale = caption_item['image/locale']\n",
    "    # Add the locale to the dictionary\n",
    "    captions_dict['locale'].append(locale)\n",
    "\n",
    "    # Get the caption in the target language\n",
    "    for lang in target_langs:\n",
    "        # Get the caption in the target language\n",
    "        caption = caption_item[f'{lang}']['caption']\n",
    "        # Get the number of captions for the image\n",
    "        num_captions = len(caption)\n",
    "        # Add the caption to the dictionary\n",
    "        captions_dict[f'{langs_abbrev[lang]}_caption'].append(caption)\n",
    "        # Add the number of captions to the dictionary\n",
    "        captions_dict[f'num_{langs_abbrev[lang]}_captions'].append(num_captions)\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "captions_df = pd.DataFrame(captions_dict)\n",
    "    \n",
    "\n",
    "# Save the dataframe to a pickle file\n",
    "captions_df.to_pickle('captions/captions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import clip\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import skimage.io as io\n",
    "import os\n",
    "\n",
    "\n",
    "def create_captions_json(path):\n",
    "    '''\n",
    "    Create a json file for the arabic and english captions\n",
    "    '''\n",
    "    # load the merged captions\n",
    "    merged_captions = pd.read_pickle(path)\n",
    "\n",
    "    # Get the arabic, english captions, French and German captions\n",
    "    arabic_captions_df = merged_captions[['image', 'arabic_caption']]\n",
    "    english_captions_df = merged_captions[['image', 'english_caption']]\n",
    "    french_captions_df = merged_captions[['image', 'french_caption']]\n",
    "    german_captions_df = merged_captions[['image', 'german_caption']]\n",
    "\n",
    "    # Split the three captions per image into three rows\n",
    "    arabic_captions_df = arabic_captions_df.explode('arabic_caption')\n",
    "    english_captions_df = english_captions_df.explode('english_caption')\n",
    "    french_captions_df = french_captions_df.explode('french_caption')\n",
    "    german_captions_df = german_captions_df.explode('german_caption')\n",
    "\n",
    "    #Rename the columns image and arabic_caption to image_id and caption\n",
    "    arabic_captions_df = arabic_captions_df.rename(columns={'image': 'image_id', 'arabic_caption': 'caption'})\n",
    "    english_captions_df = english_captions_df.rename(columns={'image': 'image_id', 'english_caption': 'caption'})\n",
    "    french_captions_df = french_captions_df.rename(columns={'image': 'image_id', 'french_caption': 'caption'})\n",
    "    german_captions_df = german_captions_df.rename(columns={'image': 'image_id', 'german_caption': 'caption'})\n",
    "\n",
    "    #Convert the dataframe to list of Dictionaries\n",
    "    arabic_captions = arabic_captions_df.to_dict('records')\n",
    "    english_captions = english_captions_df.to_dict('records')\n",
    "    french_captions = french_captions_df.to_dict('records')\n",
    "    german_captions = german_captions_df.to_dict('records')\n",
    "\n",
    "    # create a dictionary name annotations if it doesn't exist\n",
    "    os.makedirs('./annotations', exist_ok=True)\n",
    "\n",
    "    # Save the list of dictionaries to a json file\n",
    "    with open('annotations/arabic_captions.json', 'w') as f:\n",
    "        json.dump(arabic_captions, f)\n",
    "    with open('annotations/english_captions.json', 'w') as f:\n",
    "        json.dump(english_captions, f)\n",
    "    with open('annotations/french_captions.json', 'w') as f:\n",
    "        json.dump(french_captions, f)\n",
    "    with open('annotations/german_captions.json', 'w') as f:\n",
    "        json.dump(german_captions, f)\n",
    "\n",
    "\n",
    "\n",
    "def create_CLIP_embeddings_for_images(lang, clip_model_type='ViT-B/32', device='cuda'):\n",
    "    '''\n",
    "    Create the CLIP embeddings for the images and save them to a pickle file\n",
    "    '''\n",
    "    # make directory for the embeddings if it doesn't exist\n",
    "    os.makedirs('./embeddings', exist_ok=True)\n",
    "    # create the output path\n",
    "    clip_model_name = clip_model_type.replace('/', '-') \n",
    "    out_path = f\"./embeddings/{lang}_CLIP-{clip_model_name}_embeddings.pkl\" \n",
    "\n",
    "    # load the CLIP model\n",
    "    clip_model, preprocess = clip.load(clip_model_type, device=device, jit=False)\n",
    "\n",
    "    # load the annotations\n",
    "    annotations_file = f\"./annotations/{lang}_captions.json\"\n",
    "    with open(annotations_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # create list of dictionaries with the image id, the CLIP embedding and the caption\n",
    "    all_embeddings = []\n",
    "    all_captions = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        # load the image\n",
    "        d = data[i]\n",
    "        img_id = d[\"image_id\"]\n",
    "        filename = f\"./images/{img_id}.jpg\"\n",
    "        image = io.imread(filename)\n",
    "\n",
    "        # preprocess the image and encode it with the CLIP model\n",
    "        image = preprocess(Image.fromarray(image)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            prefix = clip_model.encode_image(image).cpu()\n",
    "\n",
    "        # add the index , embedding and caption to the dictionary\n",
    "        d[\"clip_embedding\"] = i \n",
    "        all_embeddings.append(prefix)\n",
    "        all_captions.append(d)\n",
    "\n",
    "    # save the dictionary to a pickle file\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump({\"clip_embedding\": torch.cat(all_embeddings, dim=0), \"captions\": all_captions}, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'captions/captions.pkl'\n",
    "create_captions_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLIP embeddings for arabic captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7367/7367 [06:23<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLIP embeddings for english captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7200/7200 [05:46<00:00, 20.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLIP embeddings for french captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8562/8562 [06:57<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLIP embeddings for german captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8643/8643 [07:01<00:00, 20.52it/s]\n"
     ]
    }
   ],
   "source": [
    "target_langs = ['arabic', 'english', 'french', 'german']\n",
    "\n",
    "for lang in target_langs:\n",
    "    print(f'Creating CLIP embeddings for {lang} captions')\n",
    "    create_CLIP_embeddings_for_images(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
